{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install livelossplot","metadata":{"execution":{"iopub.status.busy":"2023-04-25T16:27:44.649016Z","iopub.execute_input":"2023-04-25T16:27:44.649789Z","iopub.status.idle":"2023-04-25T16:27:55.839578Z","shell.execute_reply.started":"2023-04-25T16:27:44.649749Z","shell.execute_reply":"2023-04-25T16:27:55.838255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\n\n%matplotlib inline\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\nfrom tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n\nfrom IPython.display import SVG, Image\nfrom livelossplot.tf_keras import PlotLossesCallback\nimport tensorflow as tf\nprint(\"Tensorflow version:\", tf.__version__)\n","metadata":{"id":"pxvzQtUb2c3J","outputId":"f8871d2e-2816-4877-a95e-54f57167d0e0","execution":{"iopub.status.busy":"2023-04-25T16:28:20.083437Z","iopub.execute_input":"2023-04-25T16:28:20.084195Z","iopub.status.idle":"2023-04-25T16:28:20.107626Z","shell.execute_reply.started":"2023-04-25T16:28:20.084155Z","shell.execute_reply":"2023-04-25T16:28:20.106628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path='/kaggle/input/fer2013/train'\ntest_path='/kaggle/input/fer2013/test'","metadata":{"execution":{"iopub.status.busy":"2023-04-25T16:14:10.933882Z","iopub.execute_input":"2023-04-25T16:14:10.934852Z","iopub.status.idle":"2023-04-25T16:14:10.940363Z","shell.execute_reply.started":"2023-04-25T16:14:10.934799Z","shell.execute_reply":"2023-04-25T16:14:10.939168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = 48\nbatch_size = 64\n\ndatagen_train = ImageDataGenerator(horizontal_flip=True)\n\ntrain_generator = datagen_train.flow_from_directory(train_path,\n                                                    target_size=(img_size,img_size),\n                                                    color_mode=\"grayscale\",\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    shuffle=True)\n\ndatagen_validation = ImageDataGenerator(horizontal_flip=True)\nvalidation_generator = datagen_validation.flow_from_directory(test_path,\n                                                    target_size=(img_size,img_size),\n                                                    color_mode=\"grayscale\",\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    shuffle=False)","metadata":{"id":"PdbUTDNo2c3M","outputId":"c680ccb3-399c-47a8-867c-d491d0e32140","execution":{"iopub.status.busy":"2023-04-25T16:19:53.153738Z","iopub.execute_input":"2023-04-25T16:19:53.154456Z","iopub.status.idle":"2023-04-25T16:20:14.857732Z","shell.execute_reply.started":"2023-04-25T16:19:53.154418Z","shell.execute_reply":"2023-04-25T16:20:14.856626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialising the CNN\nmodel = Sequential()\n\n# 1 - Convolution\nmodel.add(Conv2D(64,(3,3), padding='same',activation='relu', input_shape=(48, 48,1)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 2nd Convolution layer\nmodel.add(Conv2D(128,(5,5),activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 3rd Convolution layer\nmodel.add(Conv2D(512,(3,3),activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 4th Convolution layer\nmodel.add(Conv2D(512,(3,3),activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Flattening\nmodel.add(Flatten())\n\n# Fully connected layer 1st layer\nmodel.add(Dense(256,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(7, activation='softmax'))\n\nopt = Adam(lr=0.0005)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"id":"e5SCvF0A2c3M","outputId":"88fe73df-0fab-43f8-ff7e-3fcc55325107","execution":{"iopub.status.busy":"2023-04-25T16:20:29.61343Z","iopub.execute_input":"2023-04-25T16:20:29.614211Z","iopub.status.idle":"2023-04-25T16:20:32.340021Z","shell.execute_reply.started":"2023-04-25T16:20:29.614138Z","shell.execute_reply":"2023-04-25T16:20:32.339157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nepochs = 15\nsteps_per_epoch = train_generator.n//train_generator.batch_size\nvalidation_steps = validation_generator.n//validation_generator.batch_size\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=2, min_lr=0.00001, mode='auto')\ncheckpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy',\n                             save_weights_only=True, mode='max', verbose=1)\ncallbacks = [PlotLossesCallback(), checkpoint, reduce_lr]\n\nhistory = model.fit(\n    x=train_generator,\n    steps_per_epoch=steps_per_epoch,\n    epochs=epochs,\n    validation_data = validation_generator,\n    validation_steps = validation_steps,\n    callbacks=callbacks\n)\n\n","metadata":{"id":"Meu97Kak2c3N","outputId":"ac1cbb58-adcc-4a4d-80c0-db650fcc6de2","execution":{"iopub.status.busy":"2023-04-25T16:28:25.487638Z","iopub.execute_input":"2023-04-25T16:28:25.488551Z","iopub.status.idle":"2023-04-25T16:39:44.41576Z","shell.execute_reply.started":"2023-04-25T16:28:25.488512Z","shell.execute_reply":"2023-04-25T16:39:44.414695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model.h5')","metadata":{"id":"FbhBNyG1ytOX","execution":{"iopub.status.busy":"2023-04-25T16:46:09.109548Z","iopub.execute_input":"2023-04-25T16:46:09.110508Z","iopub.status.idle":"2023-04-25T16:46:09.271071Z","shell.execute_reply.started":"2023-04-25T16:46:09.11047Z","shell.execute_reply":"2023-04-25T16:46:09.269981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\n\nclass FacialExpressionModel(object):\n\n    EMOTIONS_LIST = [\"Angry\", \"Disgust\",\n                    \"Fear\", \"Happy\",\n                    \"Neutral\", \"Sad\",\n                    \"Surprise\"]\n\n    def __init__(self, model):\n        self.model=model\n\n    def predict_emotion(self, img):\n        self.preds = self.model.predict(img)\n        return FacialExpressionModel.EMOTIONS_LIST[np.argmax(self.preds)]","metadata":{"id":"Y96lm4dm2c3N","execution":{"iopub.status.busy":"2023-04-25T16:42:23.009742Z","iopub.execute_input":"2023-04-25T16:42:23.010906Z","iopub.status.idle":"2023-04-25T16:42:23.01806Z","shell.execute_reply.started":"2023-04-25T16:42:23.010857Z","shell.execute_reply":"2023-04-25T16:42:23.016867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nfacec = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\nemotion_model = FacialExpressionModel(model)\nfont = cv2.FONT_HERSHEY_SIMPLEX\nclass VideoCamera(object):\n    def __init__(self,path):\n        self.video = cv2.VideoCapture(path)\n    def __del__(self):\n        self.video.release()\n    # returns camera frames along with bounding boxes and predictions\n    def get_frame(self):\n        _, fr = self.video.read()\n        gray_fr = cv2.cvtColor(fr, cv2.COLOR_BGR2GRAY)\n        faces = facec.detectMultiScale(gray_fr, 1.3, 5)\n        for (x, y, w, h) in faces:\n            fc = gray_fr[y:y+h, x:x+w]\n            roi = cv2.resize(fc, (48, 48))\n            pred = model.predict_emotion(roi[np.newaxis, :, :, np.newaxis])\n            cv2.putText(fr, pred, (x, y), font, 1, (255, 255, 0), 2)\n            cv2.rectangle(fr,(x,y),(x+w,y+h),(255,0,0),2)\n        return fr","metadata":{"id":"CD1v25Zm2c3N","execution":{"iopub.status.busy":"2023-04-25T16:42:27.81617Z","iopub.execute_input":"2023-04-25T16:42:27.817284Z","iopub.status.idle":"2023-04-25T16:42:27.879052Z","shell.execute_reply.started":"2023-04-25T16:42:27.817228Z","shell.execute_reply":"2023-04-25T16:42:27.878015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gen(camera):\n    while True:\n        frame = camera.get_frame()\n        cv2.imshow('Facial Expression Recognization',frame)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n    cv2.destroyAllWindows()\n","metadata":{"id":"n6T-DgIn2c3O","execution":{"iopub.status.busy":"2023-04-25T16:42:31.024215Z","iopub.execute_input":"2023-04-25T16:42:31.025023Z","iopub.status.idle":"2023-04-25T16:42:31.031203Z","shell.execute_reply.started":"2023-04-25T16:42:31.02498Z","shell.execute_reply":"2023-04-25T16:42:31.030063Z"},"trusted":true},"execution_count":null,"outputs":[]}]}